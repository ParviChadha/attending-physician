# FastAPI Backend

The backend captures leads from the landing page, stores them in PostgreSQL, and exposes REST endpoints the chatbot can build on.

## Requirements

- Python 3.11+
- PostgreSQL 14+ (local or hosted)

## Getting started locally

```bash
cd backend
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
cp .env.example .env  # update with your credentials
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

Create the database referenced in `DATABASE_URL` before starting Uvicorn. Tables are created automatically on startup via SQLAlchemy metadata.

## Environment variables

| Name | Description |
| --- | --- |
| `DATABASE_URL` | PostgreSQL connection string. For local smoke tests you can set `sqlite:///./dev.db`, but use the managed Postgres URL in production. |
| `ALLOWED_ORIGINS` | Comma-separated list of origins allowed to hit the API. Use bare origins only (`https://example.com`, no paths or trailing slash). |
| `API_PREFIX` | Root path for API routes, defaults to `/api`. |
| `ANTHROPIC_API_KEY` | Required to call the Attending Physician workflow (the agent copied from `ap-test-json`). |
| `RAG_ENABLED` | Set to `true` to enable the Postgres-backed retrieval-augmented workflow. Defaults to `false`. |
| `RAG_TOP_K` | How many embedding matches to pull per question (defaults to `3`). |
| `RAG_MODEL_NAME` | Hugging Face sentence-transformer used to encode questions; must match the model used to generate the stored embeddings (`NeuML/pubmedbert-base-embeddings`). |
| `APP_ENV` | Optional string for logging/observability.

## API surface

- `GET /api/health` – basic readiness probe.
- `POST /api/leads` – stores `{email, organization, message}` and returns the saved row.
- `GET /api/leads?limit=25` – fetches the most recent leads (handy for verifying deployments).
- `POST /api/chat/sessions` – starts a new Attending Physician evaluation session. Stores serialized Anthropic state in the `chat_sessions` table.
- `POST /api/chat/sessions/{id}/messages` – submits a student answer, updates the Anthropic state, and returns the JSON payload from the orchestrator.
- `GET /api/chat/sessions/{id}` – fetches the full session state so the frontend can rebuild the chat timeline after refreshes.
- `GET /api/chat/sessions/{id}/medical-questions` – returns the extracted medical questions + RAG flag for the active session.

See the autogenerated docs at `http://localhost:8000/docs` once the server is running.

## Deploying on Render (example)

1. Create a new **PostgreSQL** instance (starter plan is fine) in the same region as your web service. Copy the external connection string.
2. Create a **Web Service** from this repository, selecting the `backend` folder. Set the build command to `pip install -r backend/requirements.txt` and the start command to `cd backend && uvicorn app.main:app --host 0.0.0.0 --port 10000`.
3. Add environment variables: `DATABASE_URL` (from step 1) and `ALLOWED_ORIGINS` (e.g., `https://<user>.github.io/attending-physician`).
4. Deploy. Render gives you a public HTTPS URL you can set as `VITE_API_BASE_URL` in the frontend.

Any other PaaS (Railway, Fly, Azure Container Apps, etc.) works as long as the environment variables are provided.

## RAG data pipeline

1. Generate or refresh embeddings locally with the Jupyter notebook in `~/Downloads/ap-test-json2/embed_to_sqlite.ipynb`. It writes a portable SQLite cache (`pubmedqa_embeddings.db`).
2. Use the helper script to push those embeddings into Render Postgres:

   ```bash
   cd ~/Desktop/attending-physician
   backend/.venv/bin/python backend/scripts/upload_embeddings.py \
     --postgres-url "postgresql://<user>:<pass>@<host>:5432/<db_name>" \
     --sslrootcert isrgrootx1-selfsigned.pem
   ```

   The script is resumable via `--offset` and uses `ON CONFLICT` upserts so you can run it again after refreshing the SQLite file.
3. Flip `RAG_ENABLED=true` on your FastAPI deployment. The service will lazily load the sentence-transformer model and query the `medical_embeddings` table via pgvector to augment evaluations with medical context.
